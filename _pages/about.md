---
permalink: /
title: "About Me"
---

Wenjie Wang  is an assistant Professor (tenure-track) at School of Information Science and Technology in the ShanghaiTech University. Dr.Wang completed her Ph.D. in 2023 at [Emory University](https://www.emory.edu/home/index.html) (@Atlanta, US) under the supervision of [Dr.Li Xiong](https://www.cs.emory.edu/~lxiong/). Before that, she received the Bachelor degree at [Huazhong University of Science and Technology](https://english.hust.edu.cn/)(@Wuhan, China) in 2017. As the first or corresponding author, Dr.Wang has contributed to more than 20 papers in top-tier journals and conferences. 

Her major research interest can be listed as:
* Safety Alignment of LLM: Ensuring model outputs consistently adhere to ethical guidelines, avoid harmful content, and respect human intent, even in adversarial scenarios. 
* Personlized Alignment of LLM: Adapting LLMs to align with individual usersâ€™ values, preferences, and communication styles.
* AI Agent Safety: Studying the robustness of Agent safety from the perspective of perception, reasoning, planning, action and multi-agent collaboration. 
* Privacy Preserving LLM: Differential Privacy, Machine Unlearning, Federated Learning

### æˆ‘ä»¬æ­£åœ¨æ‹›2026ç§‹å­£å…¥å­¦çš„ç¡•å£«å’Œåšå£«ç ”ç©¶ç”Ÿï¼Œæ¬¢è¿å¯¹ä»¥ä¸Šæ–¹å‘æ„Ÿå…´è¶£çš„åŒå­¦é™„ä¸Šç®€å†è”ç³»æˆ‘wangwj1@shanghaitech.edu.cn.

## About ASPIRE Lab 
<img src="/images/1Lablogo.png" width="400" height="200">

The AI Security, Privacy, and Robustness Lab (ASPIRE LAb), led by Dr. Wenjie Wang, is a pioneering research group dedicated to enhancing the responsibility, reliability, privacy, and trustworthiness of cutting-edge AI technologies, particularly Large Language Models (LLMs), Multi-Modal models and AI Agents. The ASPIRE lab's mission is to  develop novel techniques and methodologies that address the unique challenges posed by the increasing complexity of modern AI systems.

## News
[20250516] Two papers are accepted to ACL2025ğŸ‰

[Yi Wang, Fenghua Weng, Sibei Yang, Zhan Qin, Minlie Huang, Wenjie Wang. DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing.](https://arxiv.org/abs/2502.11647)

[Yukai Zhou, Jian Lou, Zhijie Huang, Zhan Qin, Yibei Yang, Wenjie Wang. Don't Say No: Jailbreaking LLM by Suppressing Refusal.](https://arxiv.org/abs/2404.16369)

[20241224] MMJ-Bench is accepted to AAAI2025ğŸ‰

[Fenghua Weng, Yue Xu, Chengyan Fu, Wenjie Wang. MMJ-Bench : A Comprehensive Study on Jailbreak Attacks and Defenses for Multimodal Large Language Models.](https://arxiv.org/abs/2408.08464)

[20240922] CIDER is accepted to EMNLP2024ğŸ‰

[Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang. Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models.](https://arxiv.org/abs/2407.21659) 

[20240314] LinkPrompt is accepted to NAACL2024ğŸ‰

[Yue Xu and Wenjie Wang. 2024. LinkPrompt: Natural and Universal Adversarial Attacks on Prompt-based Language Models.](https://aclanthology.org/2024.naacl-long.360.pdf)

[20231209] IGAMT is accepted to AAAI-24ğŸ‰

[Wang, W., Tang, P., Lou, J., Shao, Y., Waller, L., Ko, Y.- an, & Xiong, L. (2024). IGAMT: Privacy-Preserving Electronic Health Record Synthesization with Heterogeneity and Irregularity.](https://ojs.aaai.org/index.php/AAAI/article/view/29491)

[20231209] Demo:Certified Toolformer is accepted to CCS2023ğŸ‰

[Yue Xu and Wenjie Wang. 2023. Demo: Certified Robustness on Toolformer.](https://dl.acm.org/doi/abs/10.1145/3576915.3624362)

[20230214] Start my career at ShanghaiTech University on Valentine's DayğŸ‰ğŸŒ¹
